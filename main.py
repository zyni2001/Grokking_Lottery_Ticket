# -*- coding: utf-8 -*-
"""“modulo_addition_lottery.ipynb”的副本

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qffP8TrBP4Z5fFhVBMiMm7-x1D1Lur1I
"""

import torch
from torch import nn, optim
import random
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# import plotly.express as px
import torch.nn.init as init
import pandas as pd
import pruning

torch.cuda.is_available()

np.set_printoptions(precision=4, suppress=True)
torch.set_printoptions(precision=4, sci_mode=False)

def prepare_data(D, H):
    data = [(a, b, (a + b) % D) for a in range(D) for b in range(D)]
    random.shuffle(data)

    train_data = data[:H]
    test_data = data[H:]

    train_x = []
    train_y = []
    #sd = 0.1
    #aug_times = 10
    for a, b, c in train_data:
        v = torch.zeros(1, D * 2)
        v[0, a] = 1 #one-hot encoding
        v[0, D + b] = 1
        v2 = torch.zeros(1, D)
        v2[0, c] = 1
        train_x.append(v)
        train_y.append(v2)
        #for _ in range(aug_times):
        #    v_tmp = torch.normal(0, sd, size=(1, 2*D))
        #    train_x.append(v+v_tmp)
        #    train_y.append(v2)
        #train_y.append(torch.tensor([c], dtype=torch.long))
    train_x = torch.concat(train_x)
    train_y = torch.concat(train_y)
    print(train_x.shape)


    test_x = []
    test_y = []
    for a, b, c in test_data:
        v = torch.zeros(1, D * 2)
        v[0, a] = 1
        v[0, D + b] = 1
        v2 = torch.zeros(1, D)
        v2[0, c] = 1
        test_x.append(v)
        test_y.append(v2)
        #test_y.append(torch.tensor([c], dtype=torch.long))
    test_x = torch.concat(test_x)
    test_y = torch.concat(test_y)

    train_x = train_x.cuda()
    train_y = train_y.cuda()
    test_x = test_x.cuda()
    test_y = test_y.cuda()

    _, tr_vec = train_y.topk(1, dim=1)
    _, te_vec = test_y.topk(1, dim=1)

    return train_x, train_y, test_x, test_y, tr_vec, te_vec

class NN(nn.Module):
    def __init__(self, D, H, width):
        super().__init__()
        self.phi = nn.Parameter(torch.randn(D, width)/np.sqrt(width))
        self.psi = nn.Parameter(torch.randn(D, width)/np.sqrt(width))
        self.w = nn.Parameter(torch.randn(width, D)/np.sqrt(width))
        #self.b_in = nn.Parameter(torch.zeros(1000))
        #self.b_out = nn.Parameter(torch.zeros(D))
        self.relu = nn.ReLU(inplace=True)
    def forward(self, x):
        return self.relu(x @ torch.cat((self.phi, self.psi), dim=0)) @ self.w


def train(mynn, train_x, train_y, test_x, test_y, tr_vec, te_vec):
    ce = nn.MSELoss()
    #ce = nn.CrossEntropyLoss()
    ETA = 10.0
    #opt = optim.SGD(mynn.parameters(), ETA, weight_decay=1e-4) #1e-9
    opt = torch.optim.SGD(mynn.parameters(), lr=ETA, weight_decay=0.0)
    tr_acc = []
    te_acc = []
    tr_loss = []
    te_loss = []
    for t in range(10000):
        opt.zero_grad()
        #training set
        out = mynn(train_x)
        _, pred = out.topk(1, dim=1)
        acc1 = (pred == tr_vec).float().mean().detach().cpu().numpy()
        tr_acc.append(acc1)
        #test set
        out2 = mynn(test_x)
        _, pred2 = out2.topk(1, dim=1)
        acc2 = (pred2 == te_vec).float().mean().detach().cpu().numpy()
        te_acc.append(acc2)
        #training loss
        loss = ce(out, train_y)
        #loss = ce(out, tr_vec)
        tr_loss.append(loss.detach().cpu().numpy())
        #test loss
        loss2 = ce(out2, test_y).detach().cpu().numpy()
        #loss2 = ce(out, te_vec).detach().cpu().numpy()
        te_loss.append(loss2)
        print(t, acc1, acc2, loss.detach().cpu().numpy(), loss2)
        loss.backward()
        opt.step()
    
    return tr_acc, te_acc, tr_loss, te_loss

def plot_results(tr_acc, te_acc, tr_loss, te_loss):
    fig, axs = plt.subplots(1, 2, figsize=(12, 3))
    axs[0].plot(tr_acc, linestyle='-', label='train')
    axs[0].plot(te_acc, linestyle='-', label='test')
    axs[0].set_xlabel('epochs')
    axs[0].legend()
    axs[1].plot(tr_loss, linestyle='-', label='train')
    axs[1].plot(te_loss, linestyle='-', label='test')
    axs[1].set_title('Loss')
    axs[1].set_xlabel('epochs')
    axs[1].legend()
    plt.tight_layout()
    plt.savefig('loss.png')
    plt.show()

if __name__ == '__main__':
    #### modulo addition task
    D = 73       #mod
    alpha = 0.8  #ratio of train data
    H = round(D*D*alpha) #sample size
    te_num = D*D - H

    ### load data
    train_x, train_y, test_x, test_y, tr_vec, te_vec = prepare_data(D, H)

    ### define model
    width = 512
    mynn = NN(D, H, width).cuda()
    pruning.add_mask(mynn)

    ### training and test
    tr_acc, te_acc, tr_loss, te_loss = train(mynn, train_x, train_y, test_x, test_y, tr_vec, te_vec)

    ### plot results
    plot_results(tr_acc, te_acc, tr_loss, te_loss)

